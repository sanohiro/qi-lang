
• ざっと確認した限り、Value 本体と Env まわりは im::Vector / im::HashMap に置き
  換わっていて、評価系での clone も構造共有されるようになっていました。永続構造
  化が特に効く領域（値リスト、マップ、環境、クロージャ閉包）はすでに適用済みと言
  えます。

  気になった残りのポイントは以下ぐらいです。

  - Env が依然として Arc<RwLock<Env>> を親に持ち、set 時にロック越しで更新してい
    ます。im::HashMap の構造共有が効くなら、ロックなしで Arc<EnvNode> を差し替え
    る Persistent 環境に寄せられるので、今後スレッドセーフ性より immutability を
    重視する場合は検討すると良さそうです。（現状の COW でも安全ではあります。）
  - 各ビルトインで一時的に Vec や std::collections::HashMap を使って結果を貯め、
    最後に .into() で永続構造に変換している箇所（例: src/builtins/list.rs:149 や
    src/builtins/hof.rs:264）は引き続き残っています。これは最終的に Value::List/
    Map に入る段階で Vector / HashMap へ変換されるので問題はありませんが、より
    徹底するなら im::HashMap/im::Vector を直接使って組み立てると「途中での余分な
    clone が減る」ケースがあります。
  - AST や引数コレクション (FnParam, Expr::Vector など) は依然 Vec のままです
    が、これは構文木を構築して保持する用途なのでシーケンシャルに Vec のままでも
    妥当です。

  以上を踏まえると、「まだ persistent にすべきなのに Vec/HashMap を保持してい
  る」実体は今のところ見当たりません。あとは必要に応じて Env のロック構造をどう
  するか、ビルトイン内部でのバッファ生成をもう少し Vector::new().push_back() 系
  に寄せるか、といった改善余地があるくらいです。

 - src/eval.rs:976 で get_function_name が毎回グローバル環境を線形走査してお
    り、プロファイラONで大量に呼ばれると O(n) ルックアップがボトルネックにな
    ります。関数生成時に名前を Function に埋めておくか、HashMap<Arc<Function>,
    String> の逆引きテーブルを用意するとプロファイル計測時の負荷を大きく減らせ
    ます。
  - src/builtins/http.rs:260 はリクエストごとに Client::builder() からクライア
    ントを生成するので、TLS 初期化・スレッドプール構築が毎回走ってしまいます。
    LazyLock<Client> などで共有インスタンスを持ち回すだけで I/O 系のスループット
    が改善します。
  - Value::Symbol / Value::Keyword / Value::String が全て String（ヒープ確保）な
    ので、解析・実行中に同じ識別子を繰り返し生成するとメモリが肥大化します。イン
    ターンテーブル（Arc<str> や symbol_table.intern(&str)）を入れると GC のない
    Rust ベース言語でもリークを抑えられます。特に src/parser.rs の parse_symbol
    が to_string() を多用しているので効果が高いです。
  - 永続構造になっても src/builtins/list.rs:149 などで一時的に Vec/
    std::collections::HashMap を組み立てて .into() しています。ホットパス
    （frequencies, partition-by など）では im::HashMap::with_capacity や
    Vector::from を直接使うと余計な再配置を減らせます。
  - 各種ビルトインで Vec::new() から push している箇所（例: src/builtins/
    list.rs:63, :92）は、with_capacity(min_len * 2) のように事前確保を入れると
    コピー回数が減ります。Persistent Vector でもビルド時は内部で Vec を使うため
    キャパ確保は有効です。
  - Env は im::HashMap に置き換わりましたが、親を Arc<RwLock<Env>> で持っている
    （src/value.rs:326）ので set のたびにロックが発生します。ランタイムのデータ
    競合がなければ Arc<EnvNode> に差し替えて lock-free な永続環境にするとより一
    貫した immutability になり、読み取り性能も上がります。
  - 内部エラーメッセージが String を都度生成している箇所 (src/eval.rs:642, src/
    builtins/io.rs:207 など) は Arc<str> や Cow<'static, str> に統一するとア
    ロケーションを減らせます。合わせて i18n 辞書を LazyLock<HashMap<MsgKey,
    &'static str>> にすると lookup も軽くなります。

• いまの i18n 実装は初期化 1 回とはいえ、HashMap<(Lang, MsgKey), &'static str>
  を構築して都度 look‐up、String::replace でテンプレート補間…とオーバーヘッドが
  大きめです。高速化のアイデアとしては次のようなものが考えられます。

  1. 配列/インデックス化への切り替え
      - MsgKey / UiMsg に #[repr(usize)] を付けて添え字化し、static MSG_EN:
        [&'static str; N] のような配列に直接アクセスすると HashMap を丸ごと削れ
        ます。Lang ごとに別配列を持ち、Messages は「現在言語の配列へのポインタ」
        だけ持てば look‐up は定数時間かつ分岐なしになります。
      - さらに match lang { Lang::En => EN_MSGS[key as usize], Lang::Ja =>
        JA_MSGS[key as usize] } という形にすれば、CPU ブランチ予測にも優しくなり
        ます。phf の静的ハッシュを使う手もありますが、列挙体の添え字化の方がメモ
        リ局所性が高いです。
  2. テンプレートの事前パース
      - 現状 fmt/fmt_ui は result.replace("{0}", arg) をループするたびに新しい
        String を生成しています。
      - &'static [&'static str] にプレースホルダ区切りで事前分割（例：
        ["undefined variable: ", ""]）し、write! でバッファに連結するとアロケー
        ションは最初の String::with_capacity() のみで済みます。Rust 流に行くなら
        Cow<'static, str> や tinytemplate のような軽量テンプレータも選択肢です。
  3. Lang 切り替えコストの削減
      - 今は init() 時に Lang::from_env() を呼ぶだけですが、QI_LANG/LANG を実
        行の途中で変えたいケースがあるなら、OnceLock<(&'static [&'static str],
        &'static [&'static str])> にして set_lang(Lang) で切り替える API を用意
        し、env 参照を一度で済ませるほうが効率的です。
      - とくに REPL で QI_LANG を変更して init() を再読込しない場合は、Messages
        自体を OnceLock ではなく RwLock + Arc にしてホットスワップできる構造にす
        るとユーザビリティも上がります。
  4. 生成コードの自動化
      - メッセージ定義が大きいので、build.rs で yaml/json から const 配列を生成
        するようにし、ビルド時に展開したほうが読み込み時のコストゼロで済みます。
        Clojure の clj-i18n と同じ発想です。
  5. その他細かな最適化
      - 現在 Lang::from_env() で std::env::var を 2 回呼んでおり、init() でしか
        使わないなら init() 内で結果を保持し Messages に埋め込むとよいでしょう。
      - msg() などで初期化されていない場合 "message system not initialized" を返
        していますが、debug_assert にして release では unreachable!() にしてしま
        うと本番時に枝刈りされます。

  以上のように、配列による O(1) 参照＋テンプレート事前パースを行うだけでも、i18n
  メッセージ取得の速度とメモリ効率はかなり改善します。

• Lexer

  - src/lexer.rs:38 で入力を Vec<char> に変換していますが、UTF-8 を 1 文字ず
    つ copy しているため高コストです。&str のままオフセットを進めるか &[u8] と
    memchr を使う構成にすると、割り算不要でキャッシュ効率も良くなります。
  - src/lexer.rs:205 などの read_symbol_or_keyword は都度 String を構築していま
    す。シンボル/キーワードをインターン（SymbolInterner のようなテーブル）する
    と、同じ識別子が大量に出るケースでアロケーションと比較コストを抑えられます。
  - tokenize (src/lexer.rs:540) は一括で Vec<Token> を返す設計ですが、REPL で
    はトークンを逐次処理できるとメモリピークを削減できます。Iterator<Item =
    Result<Token>> を返し、必要に応じてパーサ側でバッファリングするアプローチも
    検討の余地があります。

  Parser

  - parse_* 系（例: src/parser.rs:185）が String を clone しながら Expr::Symbol
    を作っています。ここも intern を活用すれば、AST サイズを縮められます。
  - AST の Expr::Vector, Expr::Map が Vec のままで、永続ベクタに変換するのは評価
    時です。パーサ段階で im::Vector を使うと、巨大 AST の複製（マクロ展開など）
    でコピーコストを抑えられます。
  - SPECIAL_FORMS を LazyLock<HashSet<&'static str>> で判定 (src/parser.rs:14)
    していますが、ここは match name.as_str() のテーブル生成や phf::Set に切り替
    えることで分岐コストを一定にできます（parser のホットパス向け）。
  - ドキュメント文字列処理 (src/parser.rs:212) で Some(self.parse_expr()?) と
    AST を丸ごと保持していますが、単なる String に限定されるならパース段階でバリ
    デーションして Expr より軽量な型に落とす選択もあります。

  Evaluator

  - apply_function (src/eval.rs:993) が args.to_vec() で必ず新しい Vec を作成し
    ています。SmallVec<[Value; 8]> や Cow<[Value]> を採用すると小さな呼び出しの
    オーバーヘッドが減ります。
  - Env は im::HashMap 化されていますが、親参照を Arc<RwLock<Env>> で保持 (src/
    value.rs:333) しているため、set のたびにロックが必要です。永続マップのポイン
    タを Arc<EnvNode> で差し替えるロックレス実装にすると、関数呼び出しや let の
    ネストがより軽量になります。
  - get_function_name (src/eval.rs:1002) はプロファイル用に global env を線形
    走査しており、hot path で O(n)。関数定義時に名前を Function に埋め込むか、
    HashMap<Arc<Function>, String> の逆引きを持つだけで計測時の負荷が大幅に下が
    ります。
  - 末尾再帰 (recur) の処理 (src/eval.rs:1542) はまだループ変換されていません。
    Clojure/Gleam に倣い、recur を評価時にトランポリン化すると深い再帰でもスタッ
    ク消費を抑えられます。
  - Value::Symbol や Value::Keyword が String のまま (src/value.rs:27) なので、
    評価中に何度も比較が発生する箇所（ENV look-up 等）では intern 済み ID で比較
    した方が高速です。

  共通

  - エラーメッセージ生成 (src/i18n.rs) は String::replace を繰り返すため、構造体
    に差し込むテンプレートを事前分割し write! で連結すると割り込みアロケーション
    が減ります。
  - I/O 系ビルトイン（例: src/builtins/io.rs:207）は std::collections::HashMap
    を都度生成しています。HashMap::with_capacity や FxHashMap（rustc_hash）に切
    り替えるだけでも小さなオプション解析で効果が出ます。

  これらのチューニングで lexer/parser/eval の CPU 使用とメモリの削減が狙えます。

• - src/builtins/string.rs:44, :171, :278 などで
    s.chars().collect::<Vec<char>>() → iter() し直しています。大きめの文字列だと
    都度 Vec<char> が丸ごと確保されるので、char_indices() を使ってスライス位置を
    求めつつ &s[start..end] を借用する実装にするとヒープ確保が消えます（UTF-8 境
    界チェックも内蔵されています）。
  - src/builtins/string.rs:222 ほか pad_left/right/pad は
    pad_char.to_string().repeat(pad_count) を2回生成しています。
    String::with_capacity(width) を確保して push で埋めるか、
    std::iter::repeat(pad_char).take(pad_count).collect::<String>() を一度だけ行
    い push_str する方がコピーを減らせます。
  - src/builtins/string.rs:332 の native_squish は split_whitespace()
    → Vec<&str> → join と中間ベクタを必ず作ります。let mut out =
    String::with_capacity(s.len()); を確保し、空白ブロックをスキップしながら
    write! するほうが分割・結合のアロケーションを避けられます。
  - src/builtins/string.rs:463 以降のケース変換 (snake/camel/kebab/pascal)
    は split_words が Vec<String> を返し、後段でも都度 to_lowercase()/
    to_uppercase() を呼んでいます。split_words を Vec<(&str, bool)> など借用ベー
    スに変え、最終的な String を with_capacity で一度だけ生成すると GC 圧を大き
    く削れます。
  - 正規表現系（native_re_find など src/builtins/string.rs:1283 以降）は毎回
    Regex::new でコンパイルしているので、once_cell::sync::Lazy + キャッシュテー
    ブルで同じ正規表現を再利用させると Web ワークロードで効きます。正規表現リテ
    ラルを多用するなら LRU キャッシュをぶら下げるだけでも効果大です。
  - native_split / native_lines / native_words（例: src/builtins/
    string.rs:20, :150, :186）は Vec<Value> を経由してから
    Value::Vector(parts.into()) に変換しています。直接 im::Vector::from_iter
    を使えば中間 Vec の確保を省けますし、要素数が分かっている場合は
    Vector::with_capacity（im_rc の場合 vector! マクロ）で前取りすると高速です。



• - シンボル/キーワードのインターン
    現状 Value::Symbol / Keyword が String をそのまま保持しているため、同じ
    識別子が何度もヒープ確保されます。SymbolId(u32) を返すインターンプール
    （once_cell::sync::Lazy<SymbolTable> + DashMap<String, u32>など）を導入す
    ると、比較やハッシュ計算も整数で済み高速化・省メモリにつながります。REPL や
    Web ルート処理で同名の変数・キーが大量に出る用途で顕著に効きます。
  - 文字列の共有管理
    Value::String も一文字列ごとに String を複製しています。
    Arc<str>（std::sync::Arc<[u8]> + strビュー）に統一すると、同じ文字列を
    複数値に詰めても本体は共有されます。外部との境界で String に戻す箇所のみ
    Arc::clone か to_string() を使う設計にするとコピーを非常に減らせます。
  - 文字列プールの分離
    状態管理が許すなら「インターンは静的」「実行中の動的文字列は
    StringPool（bumpalo::Bump や StringInterner）」という二層構成も有効です。Web
    リクエストごとに String が大量に生まれて捨てられる場合、bumpalo のようなア
    リーナを活用すると Vec::new() 連続でのヒープ断片化を抑えられます（リクエスト
    終了時にアリーナを破棄）。
  - UTF-8 スライスを活用
    Lexer/Parser/Evaluator で s.chars().collect::<Vec<char>>() した上でスライス
    している箇所が多く、O(n)メモリを都度確保しています。&str の char_indices()
    や get(start..end) を使って「UTF-8 境界のインデックスだけ計算 → 借用参照をそ
    のまま返す」実装に切り替えると大幅に軽くなります。
  - 文字列結合の最適化
    pad_*, replace_first, truncate など文字列を何度も String に変換して連結して
    いるところは String::with_capacity(推定長) を使って push_str で詰めるだけで
    アロケーション回数を減らせます。Web のレスポンス生成などで顕著に効くので、
    [@]繰り返し/整形系の全関数を見直す価値があります。
  - 正規表現キャッシュ
    native_re_* を含む全正規表現が呼び出しごとに Regex::new でコンパイルされて
    います。once_cell::sync::Lazy<DashMap<String, Regex>> などでパターンをキャッ
    シュし、繰り返し呼ばれる文字列フィルタが格段に高速化します（Web入力のバリ
    デーション系で重要）。
  - Request/Response 文字列の扱い
    HTTP/DB/ログなどのビルトイン内部で HashMap<String, Value> を組み立てて都度
    String を clone しています。Arc<str> ベースになればここも共有され、ボディ文
    字列を Arc<Vec<u8>> にして遅延デコードするなど、Web で大きな Payload を扱う
    際の効率も上げられます。
  - エンコーディング/UTF-8 変換
    Web 想定なら encoding_rs（encoding-extended feature）での decode/encode を一
    度のバッファ確保で済ませるよう Vec<u8> を with_capacity しておくと良いです。
  - 再利用可能な SmallVec
    ビルトインで引数を Vec<Value> にまとめ直している箇所（apply_function など）
    を smallvec::SmallVec<[Value; 4]> に置き換えると、小さな文字列操作（多くの場
    合 2〜3 個の引数）でヒープ確保が生じません。

  これらを総合すると、文字列の「インターン + 共有 + 事前容量確保 + キャッシュ」
  を徹底することが、Web 志向の Qi にとって速度・メモリ両面で効いてくるポイント
  です。

• List/Vector 周りはいま im::Vector を使っていて永続化はできていますが、まだ速度
  やメモリ効率を詰められるポイントがあります。主な改善案は以下のとおりです。

  - List を ConsList に
    Value::List を im::Vector<Value> で表現していると cons/rest が
    常にコピー（O(n)）になりがちです。im::list::List<Value> あるいは
    im::conslist::ConsList を使えば cons/rest/push_front が O(1) で動くので、
    リスト中心のコードパスが一気に軽くなります。Vector はランダムアクセス向け、
    List は前寄せの構造で使い分けると良いです。
  - Vector の slicing API を活用
    ビルトインの多く（take-while, drop-while, chunk, truncate 等）が
    Vec::new()→push→.into() という形で一旦エフェメラルな Vec をこしらえていま
    す。im::Vector には split_at, slice, append, Vector::from などがあるので、
    items.split_at(index) で左右を共有したまま返す、Vector::from_iter を直接使
    う、といった書き方に切り替えると追加のヒープ確保を減らせます。
  - im::Vector の小配列最適化を使う
    Vector::new() は実際には空の共有ノードを返すので、Vec::new() と違い
    push_back も O(1) です。ただ extend のたびに一時 Vec を経由すると意味が薄れ
    るので、for で push_back よりも Vector::from_iter を優先すると北向きのパスで
    速くなります。
  - ベクタを裏で借用するユーティリティを用意
    「Vec<Value> を得たい」ケースが多い場合、Value::as_vector() のよう
    に &Vector<Value> を借用で返すアクセサを提供すると、ビルトイン側で
    items.iter().cloned() から Vec をわざわざ作る必要がなくなります。モジュール
    間で構造を共有できるためメモリ消費とコピー回数が減ります。
  - List/Vector の比較・反復を最適化
    Value::List と Value::Vector の PartialEq は要素ごとの比較ですが、im::Vector
    は内部ノードが共有されているため ptr_eq を先にチェックするだけで多くの比較が
    ショートサーキットできます。同様に len() チェックや iter() の順序最適化も挿
    入すると細かい改善が見込めます。
  - 環境の永続化を徹底する
    現在 Env は im::HashMap を持ちつつ親を Arc<RwLock<Env>> で指しています。ここ
    を Arc<EnvNode> 形にすると、set でロックを取り直す必要がなくなり、関数呼び出
    しや let のたびに起こるコピーがさらに軽くなります。永続データ構造の利点をフ
    ルに活かすなら検討したい部分です。
  - SmallVec などとの相性
    逆に短命な可変ベクタ（eval 内部での一時引数）には smallvec::SmallVec<[Value;
    4]> を使い、永続ベクタへは最後に .into() するのが効率的です。小サイズの
    allocate を避けつつ永続構造へ返すラインができます。
  - ベンチマークとプロファイルで確認する
    永続構造は理論的に効率的ですが、実装箇所によっては結果的に Vec を行き来して
    いるケースもあるため、cargo bench や perf、dhat でどこでコピーが発生している
    かを確認しながら適用範囲を広げるのが確実です。

  以上のように、永続構造自体は導入済みでも「途中でエフェメラルな Vec/HashMap
  に落ちてしまう」箇所が残っていると恩恵が薄いので、可能な限り API レベルで
  Vector/List を直接扱うようリファクタしていくと速度・メモリ両面でさらに伸びしろ
  があります。

- 整数演算ホットパスの強化（src/builtins/core_numeric.rs）
    現状の native_add/native_sub/native_mul は毎回 args をループしつつ match
    で型チェックしています。args.iter().try_fold(0_i64, |acc, v| match v
    { Value::Integer(n) => acc.checked_add(*n).ok_or(...) , _ => Err(...) })?
    のように try_fold を使えば、最初に非整数が出た瞬間に早期終了でき、また
    checked_* 系でオーバーフローも拾えます。さらに args が 2 個だけの場合はイン
    ラインで演算する（if args.len()==2 { … }）パスを用意すると多用される 2 項演
    算に分岐が乗らず速くなります。
  - 比較系の共通化
    <, >, <=, >= それぞれで match していますが、整数比較専用ヘルパー fn
    cmp_integers(args: &[Value]) -> Result<Ordering, String> を用意し
    て native_lt などから呼び出すと、共通の型チェックを一度だけ行い早期エ
    ラー化できます。複数比較（例: (> 5 4 3)）に対応するなら、隣接ペア比較で
    iter().zip(iter().skip(1)) によるベクトル化も可能です。
  - コレクション系の O(n) コピー削減
    native_cons・native_concat・native_rest など（src/builtins/
    core_collections.rs）が im::Vector の要素を再度 push_back しているため O(n)
    でコピーしてしまっています。im::Vector は構造共有の clone が O(1) なので、
    let mut new = v.clone(); new.push_front(args[0].clone()); の形にすると push1
    回で済みます。rest なら let mut new = v.clone(); new.pop_front();、concat は
    result.clone().append(v.clone()) を使うと多段コピーを避けられます。
  - im::Vector API でのスライス活用
    take/drop/split-at 等は v.clone().split_off(index) や v.slice(range) を使う
    と分割された部分が構造共有されます。現在は iter().take(...) で新たな Vector
    を組み立てているため、頻度の高い操作ほどメモリ・時間ともに改善余地があり
    ます。
  - SmallVec で引数配列を再利用
    core の算術・比較が &[Value] をそのまま走査していますが、Evaluator 側
    (apply_function) で毎回 Vec<Value> を作っているので、小さな呼び出しが多い
    場合は smallvec::SmallVec<[Value; 4]> を導入することでヒープ確保を避けられ
    ます。
  - values_equal のショートカット
    等価比較ヘルパー（src/builtins/core_numeric.rs:204）はベクタ同士の比較に全要
    素を辿っています。im::Vector 同士なら ptr::eq → true を最初に挟むだけで共有
    ノード同士の比較を O(1) でショートカットできます。

  これらを反映すると、特に整数演算・比較・cons/rest/concat のようなホットパスで
  コピー回数が激減し、core 関数全体のスループットとメモリ効率が目に見えて向上し
  ます。
  
  • コア系でまだ手を入れられそうなポイントを整理するとこんな感じです。
  
    ### 数値・比較（core_numeric.rs）
  
    - native_add/sub/mul はすべて整数専用で、float が混ざると即エラーになります。
      Web では小数が混じる場面が多いので、ループ中に match しながら i64 累積と f64
      累積のどちらかに自動昇格するパスを入れると実用性と速度が上がります。二項演算
      の場合は最初に match (args[0], args[1]) で型を決めてしまうと分岐が減ります。
    - ループ内で match するより try_fold を使って早期にエラーを返す構造にすると、
      非整数が混ざった時に不要な比較をしなくて済みます。同時に checked_add 等を使
      えばオーバーフロー検出もでき、クラッシュを避けられます。
    - values_equal は Vector/Map の比較で必ず全要素を歩いています。im::Vector や
      im::HashMap は内部でノード共有をしているので、最初に if std::ptr::eq(...)
      { return true; } を入れてショートカットできます。これは長いコレクション比較
      で特に利きます。
  
    ### コレクション（core_collections.rs）
  
    - native_cons/native_concat/native_rest などが新しい Vector を push_back で
      構築していますが、im::Vector は clone すると O(1) で共有できるので、let mut
      new = v.clone(); new.push_front(...) のように書き換えるとコピーを一気に減ら
      せます。rest は clone().pop_front() を使えば1要素分の削除だけで済みます。
    - split, take, drop 等も iter().take() で組み直しているので
      v.clone().split_off(index) や v.slice(...) を活用すると構造共有を保ったまま
      部分列を取り出せます。
  
    ### 高階関数（core_functions.rs）
  
    - native_partial と native_comp が環境に特殊変数 __partial_args__/
      __comp_funcs__ を書き込んでいます。これだとパフォーマンス以前に汚染の
      リスクがあります。Function に新しいフィールドを追加するか、小さな enum
      FunctionBody を持たせて evaluator 側で直接扱ったほうが呼び出し時の look-up
      も減り、安全です。
    - native_apply は引数の im::Vector を Vec にコピーしてから evaluator に渡して
      います。Evaluator 側で &[Value] に直接変換できるようにすれば、ここでのコピー
      をなくせます（apply_function を Cow<[Value]> 受けにするなど）。
  
    ### 述語（core_predicates.rs）
  
    - ここは単なる matches! なので十分ですが、type_name() の呼び出しが多い部分で
      &Value を借用する accessor (Value::as_list() -> Option<&Vector<_>>) を用意す
      るとパターンの複製が減ります。
  
    ### 状態/メタ（core_state_meta.rs）
  
    - native_swap で func_args を Vec<Value> にしています。
      smallvec::SmallVec<[Value; 4]> にすると小さな更新でヒープ確保が起きません。
      Atom 操作はホットパスになりやすいので効果が出やすいです。
  
    ### 文字列（core_string.rs）
  
    - native_str で format!("{}", v) を呼ぶと Value::Display 実装が絡みますが、
      Value::to_string() は多くのケースでヒープ確保が発生します。Arc<str> ベースに
      していれば clone() で済みますし、ここもインターンや Cow の仕組みを使うと少し
      浮きます。
  
    ### I/O・論理（core_io_logic.rs）
  
    - native_print/println は Vec<String> を作って join(" ") しており、引数が多い
      とそのぶんアロケーションが増えます。String::with_capacity と write! を使って
      一気に連結した方が効率的です。ログ用途が多い Web では意外と差が出ます。
  
    ### ユーティリティ（core_util.rs）
  
    - native_to_int/native_to_float で format!("{:?}", args[0]) をエラーに埋め込
      む際に余計なヒープ確保が発生します。軽量化するなら i18n でエラーテンプレート
      に ID を埋めるだけにして、Value::type_name() と短い説明だけを書く方が効率的
      です。
    - native_now/timestamp/sleep は既に十分軽いですが、Web 応答用なら
      SystemTime::now() より Instant を使うほうがモノトニックで確実です（ただし結
      果表示が Unix 時刻なら今のままで良いです）。
  
    ### その他
  
    - 現在すべての core 関数が Result<Value, String> を返しています。エラーの
      String はヒープ確保を伴うので、Result<Value, Error> にまとめ、最後に String
      に変換するときだけフォーマットする構造にすると、多くの正常系で「エラー用の文
      字列生成」が省けます。core 系のホットパスではこれだけでかなり違います。
    - Value に as_int(), as_list() のようなボローチェック関数を追加すると、match
      のネストが浅くなり CPU ブランチ予測が良くなると同時にコードも読みやすくなり
      ます。
    - core_numeric の native_div など演算が 2 項固定の関数は、引数長をチェックした
      ら if let (Value::Integer(a), Value::Integer(b)) = (args[0], args[1]) のよう
      にトップレベルでマッチさせると分岐が一回で済みます。
  
    これらを反映すると、core 関数を多用する Web ルートや DSL 処理で体感できるレベ
    ルの速度・メモリ効率の向上が見込めます。
  
  • I/O 周りでまだ手を入れられそうなポイントをまとめるとこんな感じです。
  
    読み取り系
  
    - native_read_file は fs::read_to_string を使っているので全ファイルを一度にメ
      モリへ積みます。大きめのログや CSV を扱う場合は BufReader + read_to_end な
      どストリーミングに切り替えられる API を用意するとピークメモリを抑えられま
      す。auto_detect_encoding にそのまま Vec<u8> を渡せるようにするだけで改善でき
      ます。
    - auto_detect_encoding（encoding-extended 時）では各エンコーディングに対し
      て毎回 decode_bytes を実行しており、失敗するたびに String を生成し直して
      います。サードパーティの検出ライブラリ（chardetng 等）を挟むか、失敗時には
      Cow<'static, str> を返すようにしてアロケーションを抑えるのが良さそうです。
    - create_file_line_stream は1行ずつ String に読み込んで返していますが、Web
      でよくあるアクセログなどリングバッファ的に使うなら、ライン数が多いときに
      line.shrink_to_fit() を呼ぶか、with_capacity を使って極端な小さい/大きい行で
      も再利用できるバッファを持つようにすると割り当て数が削減できます。
  
    書き込み系
  
    - native_write_file はキーワードオプションを std::collections::HashMap に
      積んでいます。HashMap::with_capacity(args.len()/2) を使い、enum IfExists
      { Overwrite, Error, Skip, Append } のようにパースしておけば、毎回文字列比較
      をしなくて済みます。
    - 書き込み前に if create_dirs { fs::create_dir_all(..) } が走りますが、これ
      を Path::parent() で得た Option<&Path> が Some("") のケース（カレントディレ
      クトリ）も含めて判定している点は今のままでも機能します。より高速にするなら
      create_dirs が false の時に canonicalize 等の追加システムコールを呼ばないよ
      う注意すべきです。
    - write_stream / write-json 相当の処理で File::create を毎回開き直している箇所
      があります。大量のストリームを処理する場合は BufWriter を挟むと小さい書き込
      みをまとめられます。
  
    キーワード引数の解析
  
    - parse_keyword_args が std::collections::HashMap を返しています。FxHashMap や
      Vec<(String, Value)> にして args.len()/2 の容量を確保すると、キーが少数のと
      きに不要なリハッシュを避けられます。
    - さらに Value::Map にする最終段階で Value::Map(opts.into()) に入れているの
      で、最初から im::HashMap を使えばコピーを一度減らせます。
  
    バイナリストリーム
  
    - バイトストリーム (create_file_byte_stream) は Vec<Value> を生成して
      Value::Vector に変換しています。バイナリをそのまま Qi の CT モデルにマッピ
      ングするよりも、たとえば Value::Vector(Vector<Value>) ではなく Value::String
      に base64 する、Value::Bytes(Arc<Vec<u8>>) を追加すると大量の変換を避けられ
      ます。Web でバイナリレスポンスを扱うならこちらの改善が効きます。
    - CHUNK_SIZE は 4096 固定ですが、ファイルサイズによっては
      BufReader::with_capacity(n) で任意のバッファサイズを与えられるので、オプショ
      ン（io/file-stream の引数）でチャンクサイズを変えられると柔軟性が増します。
  
    クロスプラットフォーム
  
    - Path を String として扱っている箇所（例: parse_keyword_args で Value::String
      を強制）では、Windows の UNC パスなど非 UTF-8 のケースが扱えません。
      Value::Path を追加し AsRef<Path> を使えるようにするか、OsString を経由して内
      部だけで String にマップする方が安全です。Web でアップロードされたファイル名
      にマルチバイトが含まれる場合の不具合を防げます。
  
    ストリーム API の統一
  
    - 現状、バイトストリームと行ストリームで Stream を生成し、それを Value::Stream
      にラップしていますが、ストリームを引き回す際に Arc<RwLock<BufReader<File>>>
      が必要になっています。非同期 I/O を見据えるなら mpsc などでラップするより
      poll ベースの API を設計した方が良いですが、少なくとも現状でも BufReader を
      共有せず Arc<Mutex<File>> で直接 read するだけでもロック回数を減らせます。
  
    これらを踏まえると、I/O 全体で「途中の String/Vec<Value> の生成を減らす」「エ
    ンコーディング検出のコストを抑える」「キーワード引数解析を軽くする」「Path の
    扱いを OS ネイティブに寄せる」といった点を改善すれば、Web 系のワークロードで体
    感できるレベルの高速化とメモリ効率化が期待できます。
  
  
  
  • HTTP クライアント (src/builtins/http.rs)
  
    - クライアント生成は lazy_init::http_client::CLIENT で共有できるようになって
      いて良いですが、reqwest::blocking::Client は内部的に TLS/プールを持つため、
      timeout_ms != 30000 の場合にも builder() を毎回叩いています。カスタムタイム
      アウト用に DashMap<u64, Client> などで LRU キャッシュを持つと、大量の異なる
      タイムアウトを使うケースでもコストを抑えられます。
    - headers を im::HashMap<String, Value> で渡しているため、送信前に文字列化
      (to_lowercase) を行うたびに String が生成されます。ステータス同様、ヘッダ名
      を Arc<str> で持つ、もしくは http::HeaderMap を直接扱うとコピーが減ります。
    - レスポンスボディを常に String として読み取っています (response.text())、こ
      れは JSON 以外のバイナリを扱う場合に body フィールドへ格納した時点で破棄さ
      れてしまいます。Value::Vector で Bytes を保持する、もしくは Value::Map 側
      で :body-bytes も返すと Web API の付帯情報を落とさずに済みます。
    - エラー情報 (err.is_timeout, is_connect) を文字列で返していますが、将来的にハ
      ンドリングしやすくするなら Value::Keyword(":timeout") のようにシンボル化する
      と良いです（呼び出し側が case しやすくなります）。
  
    HTTP サーバー (src/builtins/server.rs)
  
    - リクエストから Qi 値 (request_to_value) を組み立てる際に
      body_bytes.collect().await で全ボディを読み切ってしまうため、ファイルアップ
      ロードなど大きなリクエストを扱うとメモリを使い切ります。Value::Stream に変換
      して遅延処理するか、:body と並列で :body-stream を渡すと柔軟性が増します。
    - クエリ/ヘッダーを HashMap<String, Value> に詰めていますが、ヘッダーが多い場
      合に String の再生成が多いです。Arc<str> に統一する、あるいは Value::Keyword
      を使うなどしてアロケーション回数を減らせます。
    - レスポンス側 (value_to_response) では body を latin1 変換しています。バイナ
      リ応答が多い Web 用途なら Bytes をそのまま保持できる Value::Bytes のような
      バリアントを追加し、変換無しで Full::new(bytes) に渡せるようにすると無駄なコ
      ピーを避けられます。
    - サーバー実行 (native_server_serve) は新しい tokio::runtime::Runtime を
      thread::spawn 内で毎回 new() しています。アプリ全体でサーバーを複数立てる場
      合、lazy_init::http_server::get_runtime() を利用して共有ランタイムを取得する
      方が効率的です。
    - ミドルウェアやルーターの判定に Value::Map を多用していますが、頻繁に clone()
      が走るため Arc<HashMap> を共有する、もしくは Value::Function に直接 router
      情報をまとめる形にすると軽くなります。
    - parse_query_params で urlencoding::decode を毎回行っているため、負荷が高い
      ケースでは部分的に percent_encoding の percent_decode_str などを使う方が高速
      です。また params.entry(key).or_default().push(...) で Vec を都度確保してい
      るので、HashMap::with_capacity(query_str.matches('&').count() + 1) などで初
      期容量を見積もるとリハッシュを減らせます。
    - ストリーミング (native_get_stream) は ReaderStream のチャンクを 4KB ずつ
      Value::Vector に変換しています。これも Value::Stream の Bytes を直接扱えるよ
      うにすれば、繰り返しの Vec::new と 8KB バッファ確保を避けられます。
  
    総じて HTTP/Server は大筋良い構造ですが、ボディ（リクエスト/レスポンス）を常に
    String へ展開しているところが最大のネックです。バイナリ/大規模データを扱う用
    途では Bytes を保持できるバリアントとストリーム API を用意すると速度・メモリの
    両面でかなり改善できますし、サーバー側は共有ランタイムの活用でコストを下げられ
    ます。
  
  
  
  

• HTTP クライアント

  - http_request は serde_json ベースで一度 Value::Map を作ってからボディ文
    字列を取り出しています。crate::builtins::json::native_stringify の戻りも
    Value::Map なので、直接 serde_json::to_string を呼ぶバイパスを用意すると中間
    構造のアロケーションを避けられます。
  - ヘッダーやエラータイプをすべて String で保持しているため、大量のリクエストで
    to_lowercase や to_string が繰り返し走ります。Arc<str> かキーワードに寄せる
    と複数レスポンス間で共有され、メモリと比較コストが下がります。
  - バイナリボディでも response.text() にしているため UTF-8 化に失敗すると空文
    字が返り、元のバイト列が失われます。Value::Bytes(Arc<Vec<u8>>) のようなバリ
    アントを追加し、JSON 以外はバイト列のまま返せるようにするのが実運用では安全
    です。
  - 非同期版は rayon::spawn で native_get を呼んでいますが、native_get 自体が
    reqwest::blocking を使うので、CPU バウンドなスレッドプールを埋めがちです。
    reqwest::blocking::Client::execute は内部でスレッドを確保するため、tokio の
    ランタイム上では Client::new() + async API に揃えた方が一貫します。

  HTTP サーバー

  - request_to_value は body.collect().await で全バイトを読みきります。大きな
    POST を扱うなら Value::Stream でチャンクを流す API を追加し、必要な場合だけ
    collect する設計にしておくとメモリ圧迫を避けられます。
  - レスポンスのボディを latin1 文字列へ変換（body.chars().map(...)）してい
    るので、Value::String に収まらないバイナリが壊れます。クライアント側と同
    様 Value::Bytes を導入し、Full::new(Bytes::from(vec)) へ直接渡す方が効率的
    です。
  - ルーティング情報やヘッダを HashMap<String, Value> で毎回複製しており、リクエ
    スト数が多いと GC のような形で負荷が掛かります。Arc<HashMap<..>> を共有した
    まま必要時だけ clone() する、あるいは im::HashMap の構造共有を活かすとヒープ
    消費を減らせます。

  DB 共通（db.rs）

  - グローバル管理 (CONNECTIONS, TRANSACTIONS, POOLS) が
    Mutex<HashMap<String, ...>> に文字列 ID を突っ込む方式です。接続 ID を
    usize にし DashMap へ切り替えるだけで look-up のボトルネックが解消しますし、
    Value::String("DbConnection:…") を返すより Value::Map や Value::Uvar に埋め
    込んだ方が変換コストが減ります。
  - params_from_value が Vec<Value> を返して都度コピーしています。
    smallvec::SmallVec<[Value; 8]> を使えば典型的な小さなパラメータセットでヒー
    プ確保を回避できますし、Value::Vector を保持したまま ToSqlOutput へ変換する
    ユーティリティを作ると変換回数を減らせます。
  - rows_to_value は Vec<Row> を im::Vector に変換しており、大規模な結果セット
    で大量の String 複製が発生します。Row を Arc<HashMap<...>> にして Value::Map
    へ移譲すれば、同じ列名が繰り返し出るケースでもシンボルを共有できます。

  SQLite ドライバー（sqlite.rs）

  - SqliteConnection::query / exec は conn.prepare を毎回行っています。
    rusqlite::Connection::prepare_cached を使えば同じ SQL の再コンパイルを避けら
    れます。短命ステートメントが多い場合でも cached は内部テーブルを持つだけなの
    で、明示的に stmt.finalize() する必要もありません。
  - バイナリ列を base64 で String にして返していますが、Web では JSON 以外の
    フォーマットも扱うため Value::Bytes として保持しておくと後段の処理が単純にな
    ります。
  - DbPool::acquire では available と in_use_count を別々の Mutex でロックし、二
    重にロックを取り直しています。parking_lot::Mutex は再入ロックには対応します
    が、available.pop() 後に self.available.lock().len() を呼ぶのは無駄が多いの
    で let total = available.len() + *in_use; のように同じロック内で計算するのが
    正攻法です。
  - Arc<Mutex<SqliteConn>> を毎回 lock() して prepare→execute しているため、同時
    実行時には接続全体が直列化されます。rusqlite はコネクション per thread を推
    奨するので、プールを前提に Arc<SqliteConn>＋call_once(|| Mutex::new(())) の
    ような細粒度ロックに分けるとスループットが改善します。

  まとめると、HTTP/Server はボディの扱いを String 前提からバイト対応に寄せつつ、
  ヘッダー/エラーを構造化するだけでメモリ節約になります。DB/SQLite は ID 管理の
  オーバーヘッドを下げ、ステートメント/パラメータ変換のコピーを減らすのが効率化
  の要所です。



• JSON (src/builtins/json.rs)

  - native_parse/native_stringify は毎回 serde_json::Value を全部構築
    してから Qi の値に変換しています。大きな配列では中間オブジェクトが
    二重化するので、json_to_value で Vec::with_capacity(arr.len()) や
    HashMap::with_capacity(obj.len()) を使って余計な再確保を避けられます。
  - serde_json::Value::String を Value::String(s.clone()) に変換しているため、
    巨大な同一キー/同一文字列が多い JSON では複数回アロケーションが走ります。
    Arc<str> やシンボルインターンを導入すると文字列共有ができ、メモリ削減に効き
    ます。
  - 失敗時の Value::Map({:error …}) は文字列化したエラーを格納するだけなので、
    利用側が case したいときに扱いづらいです。{:error {:type :parse :message …}}
    のようにタグを付けておけば呼び出し側の分岐が少しだけ軽くなります（型安全とい
    う意味でもモダン）。

  CSV (src/builtins/csv.rs)

  - parse_csv/stringify_csv は手書きのループで Vec<String> を組み立てていま
    す。標準の csv crate を使えば SIMD 最適化されたパーサー/ライターが利用で
    き、メモリ効率も改善します。特に native_csv_read_stream がファイル全体を
    read_to_string で読み込んでからイテレートしているため、真のストリーミングに
    なっていません。csv::Reader::from_path でレコードイテレータを直接 Stream 化
    するのが良いです。
  - 文字列連結 (stringify_csv) では都度 result.push() を呼んでいます。
    String::with_capacity でフィールド長に応じた初期容量を確保し、write! や
    push_str で積み上げるだけでも CPU 使用が下がります。
  - native_csv_stringify の string_fields を Vec<String> で作ってから
    stringify_csv に渡していますが、CSV 出力専用の WriterBuilder を使えば変換 +
    エスケープ処理をライブラリに任せられます（これも速度向上ポイント）。

  YAML (src/builtins/yaml.rs)

  - serde_yaml::Value::Mapping を std::collections::HashMap 経由で Value::Map に
    しています。ここも im::HashMap に直接詰めると構造共有が効き、メモリを削れ
    ます。
  - JSON 同様文字列を clone() しているので、インターン/Arc<str> 化をすると繰り返
    しキーが出る設定ファイルで恩恵があります。
  - 例外処理も Value::Map({:error …}) の形ですが、serde_yaml のエラーは Location
    を含んでいるので、:line や :column を抜き出して返せるとデバッグが楽になり
    ます。パフォーマンス面では、serde_yaml::from_str::<serde_yaml::Value> より
    Deserializer::from_str で直接 Visitor を実装したほうが中間構造を省けます。

  共通ポイント

  - 3 モジュールとも { :ok … } と { :error … } の Value::Map を返しており、呼び
    出し側は毎回 get("ok") を呼ぶ必要があります。内部で Result<Value, String> を
    使い、呼び出し時に map_ok するよう統一すれば、余計な HashMap のヒープ確保を
    削減できます。
  - 大量データを扱う場合はインターンや Arc の導入で文字列共有を進める、標準ライ
    ブラリの高速実装（csv crate など）に乗せ替えるのが速度・メモリ両面で一番効き
    ます。

• JSON (src/builtins/json.rs)

  - json_to_value / value_to_json が Vec/HashMap を毎回再確保しているので、
    with_capacity を使って要素数ぶん確保してから詰めるとコピーを抑えられます。
  - 文字列はすべて String::clone しているため、同じキーが大量に出る JSON ではア
    ロケーションが嵩みます。Arc<str> やシンボルインターンを導入して共有するだけ
    でもメモリ使用量が落ちます。
  - 成功・失敗を {:ok …}/{:error …} の Value::Map で返していますが、内部的には
    Result<Value, DbError> のように管理し、最終出口でだけマップに変換すると不要
    な HashMap ヒープ確保を避けられます。

  CSV (src/builtins/csv.rs)

  - 手書きのパーサー／シリアライザで全内容を String に積んでいるため、大きい CSV
    を扱うと丸ごとメモリに載ります。csv クレート（SIMD 最適化済み）でレコードを
    逐次処理する構成に変えると、大幅に速く・省メモリになります。
  - native_csv_read_stream が read_to_string で全読みしてからストリーム化し
    ているので、真のストリーミングになっていません。csv::Reader::from_path +
    Arc<Mutex<Reader>> のようにチャンクを順次読むと巨大ファイルでもピークメモリ
    を抑えられます。
  - stringify_csv も String::push を多用しているので、レコード数が多い場合は
    String::with_capacity(見積り) や write! を使って余分な再配置を防げます。

  YAML (src/builtins/yaml.rs)

  - JSONと同様に serde_yaml::Value → Value::Map の変換で HashMap を都度生成して
    います。im::HashMap へ直接詰める、あるいは Arc<str> を共有すると文字列キーの
    メモリを大きく節約できます。
  - エラーが {:error "YAMLパースエラー: …"} という単なる文字列なので、{:error
    {:type :parse :line … :column …}} のように位置情報を抜いて返せば呼び出し側の
    再パースを防げます。serde_yaml::Error は行・列を持っているため簡単に引き出せ
    ます。

  map モジュール (src/builtins/map.rs)

  - assoc_in_helper／dissoc_in_helper が毎回内部マップを clone して更新し
    ています。im::HashMap の構造共有を活かして entry 的な API を用意すると
    階層が深いケースでもコピーを抑えられます。Value::Map(m.clone()) とせず
    Value::Map(inner_map) を返すだけにすれば余分な clone を避けられます。
  - update_keys は変換したキーを result.insert(new_key, v.clone()) しています
    が、元マップが大きい場合は Vec に一旦詰めて collect() した方がパフォーマンス
    が良好です（im::HashMap::from_iter でまとめて作る方が早い）。

  これらの変更で JSON/CSV/YAML の巨大データや複雑なマップ操作時に、アロケーショ
  ンの削減とスループット向上が期待できます。



• 正規表現まわりで目に付く改善ポイントは以下のとおりです。

  - src/builtins/string.rs の native_re_find / re_matches / re_replace /
    re_match_groups / re_split は呼び出しごとに Regex::new でコンパイルしていま
    す。よく使うパターンが繰り返し渡されると毎回コンパイルコストが掛かりメモリも
    増えるため、once_cell::sync::Lazy + DashMap<String, Regex> などでパターンを
    キャッシュする仕組みを用意すると安定して高速化できます。
  - 同じ文字列パターンを複数 API から使うケース（split→firstなど）では、Qi 側か
    ら Regex を値として保持できるようにする（Value::Regex(Arc<Regex>) など）とコ
    ンパイル済みオブジェクトを再利用できます。これにより Regex::new のコストを1
    回に抑えられ、連鎖する正規表現操作が十分速くなります。
  - Markdown モジュール (src/builtins/markdown.rs) は Lazy<Regex> で事前コンパイ
    ル済みにしてあるので、その方針を string の正規表現 API にも適用すると統一感
    があります。
  - Regex::replace_all の戻り値を一度 String に変換していますが、大きな文字列
    の場合は String::with_capacity(text.len()) を確保して Cow の中身に応じて
    push_str する実装にするとコピー削減が見込めます。
  - 失敗時のエラー (fmt_msg(MsgKey::InvalidRegex, …)) を構造化 ({:error
    {:type :regex/invalid :message …}}) しておくと、キャッシュ導入後に失敗パター
    ンを早期スキップできます。

  これらの仕掛けを入れることで、Regex::new の繰り返しコンパイルによる CPU/メモリ
  コストを抑えつつ、ホットパスの正規表現操作がよりモダンな実装に近づきます。

• Markdown モジュール全体、ざっと読む限りでは手書きの変換と正規表現ベースの判定
  で構成されています。多くの中間 String / Vec を行き来しているので、以下のような
  改善余地があります。

  - native_markdown_join などで parts を Vec<String> にコピーしてから join して
    いるので、エントリ数が多いとヒープ再確保が目立ちます。String::with_capacity
    で容量見積もりを入れつつ write! で連結するとアロケーション回数を抑えられ
    ます。
  - native_markdown_table, native_markdown_list など、文字列を 1 行ずつ
    format! で生成しています。fmt::Write の実装を使ってその場で出力することで
    Vec<String> → join の中間を省けます。
  - native_markdown_parse は lines() を Vec<&str> に集めてからインデックスで
    走査し、各ブロック生成時に String::to_string() を繰り返しています。行が多
    い Markdown を扱う際にコピーが多くなるため、入力を &str のスライスとして借
    用するか、Cow<'a, str> にして必要時のみ所有する形にするとメモリ効率が上がり
    ます。
  - Value::Map を構築する際 String をキーにしていて、Value::String も clone し
    ています。im::HashMap 利用により構造共有は効きますが、キーやテキストは
    Arc<str> にして共有するのがよりメモリ効率的です。
  - 正規表現 (HEADER_REGEX など) は Lazy<Regex> によるコンパイル済みですが、
    regex crate を使うと capture_names などが String を生成する場合もあり、
    RegexSet で複数パターンを一括判定すると余計な captures を避けられます。
  - Markdown の AST（Value::Map）も Vec<Value> のリストを作成/変換しています。よ
    り構造化された Rust 型（構造体）を用意し、評価時だけ Value に変換するように
    するとパイプライン内でのコピーを減らせます。

  まとめると、Markdown モジュールは I/O や HTTP と同様に大量の String/Vec 生成が
  残っているため、借用ベースの処理・ String::with_capacity の活用・Arc<str> によ
  る共有を進めると高速化/メモリ削減が見込めます。
    
• 追加で手を入れられそうな箇所（これまでに触れていない部分）

  - setモジュール: src/builtins/set.rs
      - 各集合演算で HashSet<String> + format!("{:?}", item) を使って重複管理し
        ています。これは毎要素で文字列化・ヒープ確保が走るので非常に重いです。
        Value に Hash 実装を付ける（例: enum HashableValue<'a> を経由）か、新た
        に Value::hash_stable() を用意して im::HashSet に直接入れると演算コスト
        もメモリも一気に下がります。
  - Function / Env 捕捉: src/value.rs:207 付近
      - Value::Function が Env を値コピーで抱えているため、fn 定義のたびに環境
        全体を複製しています。永続マップに合わせて Arc<EnvNode>（親へのポインタ
        ＋差更新）を持つ設計に変えれば、クロージャ作成コストとメモリ消費を大幅に
        削れます。native_partial / native_comp のように環境へ一時変数を押し込む
        ラッパーも不要になり、スコープ汚染を避けつつ高速化できます。
  - 高階関数ヘルパの見直し: src/builtins/hof.rs
      - map/filter 系で Vec<Value> を組んだあと Value::List(result.into()) にし
        ている箇所が多いです。im::Vector::with_capacity(items.len()) → push_back
        または Vector::from_iter へ揃えると、ホットパスのイテレーションで余計な
        コピーを抑えられます。pmap/pfilter など並列系は Arc<im::Vector> を返す作
        りにすると結果共有もしやすくなります。
  - Value::Display / native_str: src/value.rs:516, src/builtins/
    core_string.rs:11
      - 再帰的に format! や to_string() を叩いているため、大きな構造体をログし
        たときに大量の中間 String が発生します。fmt::Write を活用し Formatter に
        直接書き込む形へ寄せると、表示処理でもヒープ確保を減らせます。native_str
        も String::with_capacity の事前見積もりで同様の効果が期待できます。
  - apply_function の引数バッファ: src/eval.rs:1084
      - 既に指摘済みの to_vec() を SmallVec<[Value; 4]> 等へ置き換える提案に加
        え、Evaluator::apply_function を Cow<[Value]> 受けにして im::Vector →
        Arc<[Value]> などの借用経路を用意すると、関数呼び出し時のコピーをさらに
        減らせます。
  - Value::Symbol / Value::Keyword のインターン
      - すでに案は出ていますが、実際に SymbolIntern を導入すると src/parser.rs
        の parse_symbol や core_predicates の matches! 判定が整数比較になり、判
        定系のパフォーマンスがかなり向上します。
  - Markdown パーサの文字列管理: src/builtins/markdown.rs
      - 行ベースで Vec<String> を作り直している部分は &str 借用に切り替え、
        Cow<'a, str> で保持するだけでもアロケーションを抑えられます。また AST を
        Rust の構造体で保持し、Value への変換は最終段だけにすると Value::Map を
        何重にもコピーしなくて済みます。

  これらを加えて調整すれば、すでに挙がっている string/map/vector/list/json/fn/
  数値・判定周りの最適化に加えて、集合処理・クロージャ捕捉・高階関数・表示・
  Markdown などでもさらに速度とメモリ効率を押し上げられます。
